{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from windwhisper import *"
   ],
   "id": "fb9c3036998f624f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# we can preload the wind speed data, otherwise, the tool will do it every time\n",
    "filepath_wind_speed = \"/Users/romain/GitHub/windwhisper/dev/fixtures/era5_mean_2013-2022_month_by_hour.nc\"\n",
    "filepath_correction = \"/Users/romain/GitHub/windwhisper/dev/fixtures/ratio_gwa2_era5.nc\"\n",
    "\n",
    "def wind_speed_data():\n",
    "    wind_speed = xr.open_dataset(filepath_wind_speed).to_array().mean(dim=\"month\")\n",
    "    correction = xr.open_dataset(filepath_correction).to_array()\n",
    "    correction = correction.sel(variable='ratio_gwa2_era5_mean_WS').interp(latitude=wind_speed.latitude, longitude=wind_speed.longitude, method=\"linear\")\n",
    "    return wind_speed #* correction\n",
    "    \n",
    "data = wind_speed_data()\n",
    "\n",
    "elevation_data = xr.open_dataset(\"../fixtures/Copernicus_DSM_90m_COG.nc\")"
   ],
   "id": "e8111c31d16c0886"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dirs = [\n",
    "    \"4x4_highhigh\",\n",
    "    \"4x4_lowlow\",\n",
    "    \"4x4_medmed\"\n",
    "]"
   ],
   "id": "ba3a130339f2694d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dfs = pd.DataFrame()\n",
    "\n",
    "for directory in dirs:\n",
    "    full_path = os.path.join(directory)\n",
    "    csv_files = glob.glob(os.path.join(full_path, \"*.csv\"))\n",
    "    \n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)\n",
    "        df['source_directory'] = directory\n",
    "        df['source_file'] = os.path.basename(file)\n",
    "        dfs = pd.concat([dfs, df], ignore_index=True)"
   ],
   "id": "bfc032841e7b8fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for scenario in dfs[\"source_directory\"].unique():\n",
    "    for polygon in dfs.loc[dfs[\"source_directory\"]==scenario, \"source_file\"].unique():\n",
    "        print(f\"Processing {scenario} - {polygon}\")\n",
    "        df = dfs.loc[\n",
    "            (dfs[\"source_directory\"]==scenario)\n",
    "            &(dfs[\"source_file\"]==polygon)\n",
    "        ]\n",
    "        df.loc[:, \"rated_power_MW\"] *= 1000\n",
    "\n",
    "        wind_turbines = {\n",
    "            f'Turbine {i}': {\n",
    "                'diameter': row['rotor_diameter'],\n",
    "                'hub height': row['hub_heights'],\n",
    "                'position': (row['lat'], row['lon']),\n",
    "                'power': row['rated_power_MW']\n",
    "            }\n",
    "            for i, row in df.iterrows()\n",
    "        }\n",
    "\n",
    "        wt = WindTurbines(\n",
    "            wind_turbines=wind_turbines,\n",
    "            wind_speed_data=data,\n",
    "        )\n",
    "        \n",
    "        noise_prop = NoisePropagation(\n",
    "            wind_turbines=wt.wind_turbines,\n",
    "            humidity=70,\n",
    "            temperature=20,\n",
    "            elevation_data=elevation_data,\n",
    "        )\n",
    "        \n",
    "        noise_analysis = NoiseAnalysis(\n",
    "            noise_propagation=noise_prop,\n",
    "            wind_turbines=wt.wind_turbines,\n",
    "        )\n",
    "\n",
    "        noise_analysis.merged_map.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "        noise_analysis.merged_map.to_netcdf(f\"{scenario}_{polygon.replace('.csv', '')}.nc\")"
   ],
   "id": "da4cc950261c543a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import xarray as xr\n",
    "arr = xr.open_dataset(\"4x4_highhigh_best_polygon_polygon_1.nc\")"
   ],
   "id": "932495ab3b677e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(arr.rio.crs)",
   "id": "56c858897802a10b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example assuming you have the dataset loaded as ds\n",
    "lon_res = np.diff(np.unique(arr.lon.values)).mean()\n",
    "lat_res = np.diff(np.unique(arr.lat.values)).mean()\n",
    "\n",
    "print(f\"Longitude resolution: {lon_res:.5f} degrees\")\n",
    "print(f\"Latitude resolution: {lat_res:.5f} degrees\")\n"
   ],
   "id": "7f29b3455378ca2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "arr[\"net\"].plot.contour()",
   "id": "cfaa443d744b0c64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "72f58f81a094751c"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
